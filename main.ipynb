{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e671ded",
   "metadata": {},
   "source": [
    "We are using the Breast Cancer Wisconsin (Diagnostic) dataset. First, we must import the data and format into training and testing datasets. The structure of our imported data (numpy arrays of individual entries) is as follows [x0 = ID number, x1 = diagnosis (label attribute), x2-x32 = mean, standard error and largest measurement of: radius (x2-x4), texture (x5-x7), perimeter (x8-x10), area (x11-x13), smoothness (x14-x16), compactness (x17-x19), concavity (x20-x22), concave points (x23-x25), symmetry (x26-x28), fractal dimension (x29-31)]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data: 455\n",
      " - Of which malignant: 167\n",
      " - Of which benign: 288\n",
      "M/B ratio in training data: 0.58\n",
      "\n",
      "Length of testing data: 114\n",
      " - Of which malignant: 45\n",
      " - Of which benign: 69\n",
      "M/B ratio in testing data: 0.65\n"
     ]
    }
   ],
   "source": [
    "#Packages\n",
    "import numpy as np\n",
    "import attributeMethods as AM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#CONSTANTS\n",
    "N = 569                                                         #Breast cancer dataset contains 569 entries\n",
    "TEST_PROP = 0.2                                                 #Proportion of data split into test set\n",
    "TRAINING_QUANT = int(np.round((1-TEST_PROP)*N))                 #Number of training samples\n",
    "TEST_QUANT = int(np.round(TEST_PROP*N))                         #Number of test samples\n",
    "D = 30                                                           #Number of attributes in input vector\n",
    "ATTRIBUTES = [\"ID\",\"Diagnosis\",\n",
    "              \"radiusMean\",\"radiusSE\",\"radiusWorst\",\n",
    "              \"textureMean\",\"textureSE\",\"textureWorst\",\n",
    "              \"perimeterMean\",\"perimeterSE\",\"perimeterWorst\",\n",
    "              \"areaMean\",\"areaSE\",\"areaWorst\",\n",
    "              \"smoothMean\",\"smoothSE\",\"smoothWorst\",\n",
    "              \"compactMean\",\"compactSE\",\"compactWorst\",\n",
    "              \"concavityMean\",\"concavitySE\",\"concavityWorst\",\n",
    "              \"conpointMean\",\"conpointSE\",\"conpointWorst\",\n",
    "              \"symmetryMean\",\"symmetrySE\",\"symmetryWorst\",\n",
    "              \"fractalMean\",\"fractalSE\",\"fractalWorst\"]         #Attribute names\n",
    "np.random.seed(39217531)                                        #Set seed to student ID\n",
    "\n",
    "#Load in cancer dataset from CSV into np array\n",
    "#4-byte floating point for real numbers: around 6-7 decimal places, sufficient for our demonstration\n",
    "data = np.loadtxt(\"wdbc.data\",delimiter=\",\",\n",
    "                              dtype={\"names\": ATTRIBUTES,\n",
    "                                     \"formats\": (\"i4\",\"S1\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\")})\n",
    "\n",
    "#Randomise & Split dataset into 80-20 train/test proportion\n",
    "randomise = np.random.permutation(N)                            #Generate random permutation of indices\n",
    "data = data[randomise]                                          #Randomise dataset order using permutation\n",
    "trainData = data[:TRAINING_QUANT]                               #Split into training data\n",
    "testData = data[TRAINING_QUANT:]                                #Split into test data\n",
    "del data                                                        #Delete intermediate variable\n",
    "\n",
    "#Refactor and isolate diagnosis attribute as 1/0: malignant=1, benign=0\n",
    "Y_train = (trainData['Diagnosis'] == b'M').astype(np.int8)\n",
    "Y_test = (testData['Diagnosis'] == b'M').astype(np.int8)\n",
    "\n",
    "#Isolate x input vectors(exclude ID and Diagnosis)\n",
    "feature_names = [a for a in ATTRIBUTES if a not in (\"ID\", \"Diagnosis\")]\n",
    "X_train = np.column_stack([trainData[name] for name in feature_names])\n",
    "X_test = np.column_stack([testData[name] for name in feature_names])\n",
    "\n",
    "del trainData, testData\n",
    "\n",
    "print(\"Length of training data:\", len(X_train))\n",
    "m_train = np.count_nonzero(Y_train == 1)\n",
    "b_train = np.count_nonzero(Y_train == 0)\n",
    "print(\" - Of which malignant:\", m_train)\n",
    "print(\" - Of which benign:\", b_train)\n",
    "print(\"M/B ratio in training data: %.2f\" % (m_train / b_train if b_train > 0 else float('inf')))\n",
    "\n",
    "print(\"\\nLength of testing data:\", len(X_test))\n",
    "m_test = np.count_nonzero(Y_test == 1)\n",
    "b_test = np.count_nonzero(Y_test == 0)\n",
    "print(\" - Of which malignant:\", m_test)\n",
    "print(\" - Of which benign:\", b_test)\n",
    "print(\"M/B ratio in testing data: %.2f\" % (m_test / b_test if b_test > 0 else float('inf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaed176",
   "metadata": {},
   "source": [
    "Decision Tree (DT): CART algorithm, Gini Impurity, stop at MAX_DEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e317e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.          0.14092094  0.13452202]\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 5              #Maximum depth of decision tree\n",
    "\n",
    "#Return array of possible thresholds using mean, median, some intervals SD away from mean for category\n",
    "def possibleThreshold(xVals):\n",
    "    mean = np.mean(xVals)\n",
    "    sd = np.std(xVals)\n",
    "    thresholds = [np.median(xVals)]\n",
    "    intervals = np.arange(-4,4,0.2).tolist()\n",
    "    for i in range(0,len(intervals)):\n",
    "        thresholds.append(mean+intervals[i]*sd)\n",
    "    return thresholds\n",
    "\n",
    "#Counts types in xData subsection and returns them in [number of benign, number of malignant] format\n",
    "#i.e. [1,3] means that there is one benign datapoint and three malignant datapoints within the given subset\n",
    "def countTypes(xData):\n",
    "    sN = []\n",
    "    for i in range (0,2):\n",
    "        type = np.where(xData==i)\n",
    "        #type = np.where(xData[:,-1]==i)\n",
    "        sN.append(len(type[0]))\n",
    "    return(sN)\n",
    "\n",
    "#Calculate gini impurity from list of proportions pN\n",
    "def gini(pN):\n",
    "    sum = 1\n",
    "    for i in range(0,len(pN)):\n",
    "        sum -= (pN[i])**2\n",
    "    return(sum)\n",
    "\n",
    "#Given numeric threshold, specified attribute and xData\n",
    "#Return lower split and upper split [xDataLower, yDataLower, xDataUpper, yDataUpper]\n",
    "def splitDatabyThreshold(xData,yData,attrCol,threshold):\n",
    "    upperFilter = xData[:,int(attrCol)]>=threshold\n",
    "    return(xData[upperFilter==False],yData[upperFilter==False],xData[upperFilter],yData[upperFilter])\n",
    "\n",
    "#Decide best threshold for given attribute\n",
    "def CART(xData,yData):\n",
    "    thresholds = possibleThreshold(xData)    #Get possible thresholds from method\n",
    "    thresholdSplits = []\n",
    "    thresholdGinis =[]\n",
    "\n",
    "    #Split data by threshold\n",
    "    for i in range(0,len(thresholds)):\n",
    "        splitPairs = splitDatabyThreshold(xData,yData,0,thresholds[i])\n",
    "        thresholdSplits.append(splitPairs)\n",
    "\n",
    "    #Eliminate thresholds that do not split any datapoints\n",
    "    for i in range(len(thresholds)-1,-1,-1):\n",
    "        if ((len(thresholdSplits[i][1]) == 0) or (len(thresholdSplits[i][3]) == 0)): #If either partition is empty, remove this threshold and split from consideration\n",
    "            thresholdSplits.pop(i)\n",
    "            thresholds.pop(i)\n",
    "    \n",
    "    if not thresholdSplits:                 #If empty (no suitable thresholds with this attribute), return nothing\n",
    "        return(None)             \n",
    "\n",
    "    #Calculate pN for each type n, calculate overall Gini Impurity for each threshold\n",
    "    for i in range(0,len(thresholds)):\n",
    "        \"\"\"         lowerX = thresholdSplits[i][0]\n",
    "        lowerY = thresholdSplits[i][1]\n",
    "        upperX = thresholdSplits[i][2]\n",
    "        upperY = thresholdSplits[i][3] \"\"\"\n",
    "\n",
    "        lowerX,lowerY,upperX,upperY = thresholdSplits[i]\n",
    "\n",
    "        pNLower = np.divide(countTypes(lowerY),len(lowerY))\n",
    "        pNUpper = np.divide(countTypes(upperY),len(upperY))\n",
    "        giniOverall = (len(lowerX)*gini(pNLower) + len(upperX)*gini(pNUpper))/(len(upperX)+len(lowerX))\n",
    "        thresholdGinis.append(giniOverall)\n",
    "\n",
    "    #Return threshold producing lowest gini impurity\n",
    "    #Best threshold value (lowest gini) and gini impurity value returned as tuple\n",
    "    chosenIndex = thresholdGinis.index(min(thresholdGinis))\n",
    "    return(thresholds[chosenIndex],thresholdGinis[chosenIndex])\n",
    "\n",
    "#Identify the best attribute at a certain partition in the data\n",
    "def bestAttribute(xCurrSplit,yCurrSplit):\n",
    "    ginis = []\n",
    "\n",
    "    #Compare the best thresholds and ginis for every attribute\n",
    "    for i in range(0,D):\n",
    "        bestThreshold = CART(xCurrSplit[:,[i]],yCurrSplit)\n",
    "        if (bestThreshold != None):\n",
    "            ginis.append([i,bestThreshold[0],bestThreshold[1]])\n",
    "        else:\n",
    "            print(bestThreshold)\n",
    "        \n",
    "    #Picks attribute with lowest gini\n",
    "    ginis = np.array(ginis)\n",
    "    if (len(ginis) == 0):\n",
    "        return(None)\n",
    "    minIndex = ginis[:,2].argmin()\n",
    "    return(ginis[minIndex])\n",
    "    #Returns [attribute,threshold value,gini]\n",
    "\n",
    "print(bestAttribute(X_train,Y_train)) #First split as illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12638db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As tree is being populated from root to leaf, queue is used to keep track of new nodes\n",
    "#Construct decision tree\n",
    "def constructDT(xTrain,yTrain):\n",
    "    #First create the root node and templates for left and right child\n",
    "    rootInfo = bestAttribute(xTrain,yTrain)\n",
    "    lowerX,lowerY,upperX,upperY = splitDatabyThreshold(xTrain,yTrain,rootInfo[0],rootInfo[1])\n",
    "    rootNode = AM.treeNode(attribute=int(rootInfo[0]),value=rootInfo[1],gini=rootInfo[2],xData=lowerX,yData=lowerY,depth=0)\n",
    "    leftChild = AM.treeNode(xData=lowerX,yData=lowerY,parent=rootNode,depth=1)\n",
    "    rightChild = AM.treeNode(xData=upperX,yData=upperY,parent=rootNode,depth=1)\n",
    "    rootNode.setLeftChild(leftChild)\n",
    "    rootNode.setRightChild(rightChild)\n",
    "\n",
    "    tree = [rootNode,leftChild,rightChild]\n",
    "    treeIndex = 3\n",
    "    #Queue to hold template nodes before their thresholds have been calculated\n",
    "    nextNode = AM.myQueue()\n",
    "    nextNode.enqueue(leftChild)\n",
    "    nextNode.enqueue(rightChild)\n",
    "\n",
    "    #Until all nodes have been added and computed\n",
    "    while (nextNode.isEmpty() == False):\n",
    "        #Dequeue the next node from the queue\n",
    "        current = nextNode.dequeue()\n",
    "        xData,yData = current.getData()                         #Get its depth and partition of the data\n",
    "        depth = current.getDepth()\n",
    "        threshold = bestAttribute(xData,yData)                  #Compute its best threshold and attribute\n",
    "\n",
    "        print(threshold)\n",
    "        if (threshold.all(None)):\n",
    "            print(\"No suitable threshold found for node at depth %d with %d samples.\" % (depth, len(yData)))\n",
    "            print(\"Class distribution in this node:\", countTypes(yData))\n",
    "\n",
    "        if (np.any(threshold)==False):                      #Triggered when data is all of one type (max purity), make leaf\n",
    "            current.setAttribute(\"LEAF\")\n",
    "            current.setValue((np.argmax(countTypes(yData)))+1)\n",
    "        elif (depth == MAX_DEPTH):                          #If max depth has been reached, stop and make leaf\n",
    "            current.setAttribute(\"LEAF\")\n",
    "            current.setValue((np.argmax(countTypes(yData)))+1)\n",
    "        else:\n",
    "            current.setAttribute(threshold[0])              #Else use the best threshold and attribute computed\n",
    "            current.setValue(threshold[1])\n",
    "            current.setGini(threshold[2])\n",
    "            lowerX,lowerY,upperX,upperY = splitDatabyThreshold(xData,yData,threshold[0],threshold[1])\n",
    "            leftChild = AM.treeNode(xData=lowerX,yData=lowerY,parent=current,depth=depth+1)         \n",
    "            rightChild = AM.treeNode(xData=upperX,yData=upperY,parent=current,depth=depth+1)\n",
    "            tree.append(leftChild)                          #And add its left and right child to queue\n",
    "            tree.append(rightChild)\n",
    "            current.setLeftChild(leftChild)\n",
    "            current.setRightChild(rightChild)\n",
    "            nextNode.enqueue(leftChild)\n",
    "            nextNode.enqueue(rightChild)\n",
    "            treeIndex += 2\n",
    "    \n",
    "    return(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e7357ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.30000000e+01 9.63141431e+02 6.87524713e-02]\n",
      "No suitable threshold found for node at depth 1 with 297 samples.\n",
      "Class distribution in this node: [276, 21]\n",
      "[13.         18.528479    0.09335932]\n",
      "No suitable threshold found for node at depth 1 with 158 samples.\n",
      "Class distribution in this node: [12, 146]\n",
      "[2.20000000e+01 1.07685710e+02 4.68106091e-02]\n",
      "No suitable threshold found for node at depth 2 with 281 samples.\n",
      "Class distribution in this node: [273, 8]\n",
      "[26.          0.18827751  0.09375   ]\n",
      "No suitable threshold found for node at depth 2 with 16 samples.\n",
      "Class distribution in this node: [3, 13]\n",
      "[ 1.         20.44119759  0.15909091]\n",
      "No suitable threshold found for node at depth 2 with 11 samples.\n",
      "Class distribution in this node: [7, 4]\n",
      "[2.00000000e+00 7.73162567e+01 3.99718508e-02]\n",
      "No suitable threshold found for node at depth 2 with 147 samples.\n",
      "Class distribution in this node: [5, 142]\n",
      "[12.          5.17731171  0.01509303]\n",
      "No suitable threshold found for node at depth 3 with 263 samples.\n",
      "Class distribution in this node: [260, 3]\n",
      "[ 1.         21.13498526  0.19145299]\n",
      "No suitable threshold found for node at depth 3 with 18 samples.\n",
      "Class distribution in this node: [13, 5]\n",
      "[ 0.         16.13122022  0.        ]\n",
      "[ 0.         16.47500038  0.        ]\n",
      "[4.         0.10853018 0.        ]\n",
      "[ 0.         13.17000008  0.        ]\n",
      "[ 0.         10.67549992  0.        ]\n",
      "[2.60000000e+01 2.09838724e-01 1.36966482e-02]\n",
      "No suitable threshold found for node at depth 3 with 145 samples.\n",
      "Class distribution in this node: [3, 142]\n",
      "[2.10000000e+01 2.94226851e+01 1.44636400e-02]\n",
      "No suitable threshold found for node at depth 4 with 262 samples.\n",
      "Class distribution in this node: [260, 2]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimate\n\u001b[0;32m     15\u001b[0m trainStart \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 16\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43mconstructDT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m trainStop \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     18\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[53], line 29\u001b[0m, in \u001b[0;36mconstructDT\u001b[1;34m(xTrain, yTrain)\u001b[0m\n\u001b[0;32m     26\u001b[0m threshold \u001b[38;5;241m=\u001b[39m bestAttribute(xData,yData)                  \u001b[38;5;66;03m#Compute its best threshold and attribute\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(threshold)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m(\u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo suitable threshold found for node at depth \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (depth, \u001b[38;5;28mlen\u001b[39m(yData)))\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass distribution in this node:\u001b[39m\u001b[38;5;124m\"\u001b[39m, countTypes(yData))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "#Provided with single test datapoint and decision tree\n",
    "#Return class estimate\n",
    "def estimateDT(xTest,tree):\n",
    "    currentNode = tree[0]\n",
    "    while (currentNode.getAttribute() != \"LEAF\"):\n",
    "        attribute = currentNode.getAttribute()\n",
    "        threshold = currentNode.getValue()\n",
    "        if (xTest[int(attribute)]<threshold):\n",
    "            currentNode = currentNode.getLeftChild()\n",
    "        else:\n",
    "            currentNode = currentNode.getRightChild()\n",
    "    estimate = currentNode.getValue()\n",
    "    return estimate\n",
    "\n",
    "trainStart = time.time()\n",
    "tree = constructDT(X_train,Y_train)\n",
    "trainStop = time.time()\n",
    "correct = 0\n",
    "DTpredictedValues = []\n",
    "\n",
    "startTime = time.time()\n",
    "for i in range(0,len(X_test)):\n",
    "    est = estimateDT(X_test[i],tree)\n",
    "    DTpredictedValues.append(est)\n",
    "    if (int(est) == int(Y_test[i])):\n",
    "        correct += 1\n",
    "accuracy = np.round(100*correct/len(X_test),2)\n",
    "endTime = time.time()\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % accuracy)\n",
    "print(\"Training time: %.2f seconds\" % (trainStop - trainStart))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
