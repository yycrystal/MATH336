{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e671ded",
   "metadata": {},
   "source": [
    "We are using the Breast Cancer Wisconsin (Diagnostic) dataset. First, we must import the data and format into training and testing datasets. The structure of our imported data (numpy arrays of individual entries) is as follows [x0 = ID number, x1 = diagnosis (label attribute), x2-x32 = mean, standard error and largest measurement of: radius (x2-x4), texture (x5-x7), perimeter (x8-x10), area (x11-x13), smoothness (x14-x16), compactness (x17-x19), concavity (x20-x22), concave points (x23-x25), symmetry (x26-x28), fractal dimension (x29-31)]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data: 455\n",
      " - Of which malignant: 167\n",
      " - Of which benign: 288\n",
      "M/B ratio in training data: 0.58\n",
      "\n",
      "Length of testing data: 114\n",
      " - Of which malignant: 45\n",
      " - Of which benign: 69\n",
      "M/B ratio in testing data: 0.65\n"
     ]
    }
   ],
   "source": [
    "#Packages\n",
    "import numpy as np\n",
    "import attributeMethods as AM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#CONSTANTS\n",
    "N = 569                                                         #Breast cancer dataset contains 569 entries\n",
    "TEST_PROP = 0.2                                                 #Proportion of data split into test set\n",
    "TRAINING_QUANT = int(np.round((1-TEST_PROP)*N))                 #Number of training samples\n",
    "TEST_QUANT = int(np.round(TEST_PROP*N))                         #Number of test samples\n",
    "D = 9                                                           #Number of attributes in input vector\n",
    "ATTRIBUTES = [\"ID\",\"Diagnosis\",\n",
    "              \"radiusMean\",\"radiusSE\",\"radiusWorst\",\n",
    "              \"textureMean\",\"textureSE\",\"textureWorst\",\n",
    "              \"perimeterMean\",\"perimeterSE\",\"perimeterWorst\",\n",
    "              \"areaMean\",\"areaSE\",\"areaWorst\",\n",
    "              \"smoothMean\",\"smoothSE\",\"smoothWorst\",\n",
    "              \"compactMean\",\"compactSE\",\"compactWorst\",\n",
    "              \"concavityMean\",\"concavitySE\",\"concavityWorst\",\n",
    "              \"conpointMean\",\"conpointSE\",\"conpointWorst\",\n",
    "              \"symmetryMean\",\"symmetrySE\",\"symmetryWorst\",\n",
    "              \"fractalMean\",\"fractalSE\",\"fractalWorst\"]         #Attribute names\n",
    "np.random.seed(39217531)                                        #Set seed to student ID\n",
    "\n",
    "#Load in cancer dataset from CSV into np array\n",
    "#4-byte floating point for real numbers: around 6-7 decimal places, sufficient for our demonstration\n",
    "data = np.loadtxt(\"wdbc.data\",delimiter=\",\",\n",
    "                              dtype={\"names\": ATTRIBUTES,\n",
    "                                     \"formats\": (\"i4\",\"S1\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\",\"f4\")})\n",
    "\n",
    "#Randomise & Split dataset into 80-20 train/test proportion\n",
    "randomise = np.random.permutation(N)                            #Generate random permutation of indices\n",
    "data = data[randomise]                                          #Randomise dataset order using permutation\n",
    "trainData = data[:TRAINING_QUANT]                               #Split into training data\n",
    "testData = data[TRAINING_QUANT:]                                #Split into test data\n",
    "del data                                                        #Delete intermediate variable\n",
    "\n",
    "#Refactor and isolate diagnosis attribute as 1/0: malignant=1, benign=0\n",
    "Y_train = (trainData['Diagnosis'] == b'M').astype(np.int8)\n",
    "Y_test = (testData['Diagnosis'] == b'M').astype(np.int8)\n",
    "\n",
    "#Isolate x input vectors(exclude ID and Diagnosis)\n",
    "feature_names = [a for a in ATTRIBUTES if a not in (\"ID\", \"Diagnosis\")]\n",
    "X_train = np.column_stack([trainData[name] for name in feature_names])\n",
    "X_test = np.column_stack([testData[name] for name in feature_names])\n",
    "\n",
    "del trainData, testData\n",
    "\n",
    "print(\"Length of training data:\", len(X_train))\n",
    "m_train = np.count_nonzero(Y_train == 1)\n",
    "b_train = np.count_nonzero(Y_train == 0)\n",
    "print(\" - Of which malignant:\", m_train)\n",
    "print(\" - Of which benign:\", b_train)\n",
    "print(\"M/B ratio in training data: %.2f\" % (m_train / b_train if b_train > 0 else float('inf')))\n",
    "\n",
    "print(\"\\nLength of testing data:\", len(X_test))\n",
    "m_test = np.count_nonzero(Y_test == 1)\n",
    "b_test = np.count_nonzero(Y_test == 0)\n",
    "print(\" - Of which malignant:\", m_test)\n",
    "print(\" - Of which benign:\", b_test)\n",
    "\n",
    "print(\"M/B ratio in testing data: %.2f\" % (m_test / b_test if b_test > 0 else float('inf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaed176",
   "metadata": {},
   "source": [
    "Decision Tree (DT): CART algorithm, Gini Impurity, stop at MAX_DEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float32(13.24), np.float32(0.123607635), np.float32(0.81962776), np.float32(1.5156479), np.float32(2.211666), np.float32(2.9076862), np.float32(3.6037064), np.float32(4.2997265), np.float32(4.9957466), np.float32(5.691765), np.float32(6.387785), np.float32(7.083805), np.float32(7.779825), np.float32(8.475844), np.float32(9.1718645), np.float32(9.867884), np.float32(10.563904), np.float32(11.259924), np.float32(11.955943), np.float32(12.651963), np.float32(13.347982), np.float32(14.044003), np.float32(14.740023), np.float32(15.436042), np.float32(16.132061), np.float32(16.828081), np.float32(17.524101), np.float32(18.220121), np.float32(18.916142), np.float32(19.61216), np.float32(20.30818), np.float32(21.0042), np.float32(21.70022), np.float32(22.39624), np.float32(23.092258), np.float32(23.788279), np.float32(24.484299), np.float32(25.180319), np.float32(25.876339), np.float32(26.572357), np.float32(27.268377)]\n"
     ]
    }
   ],
   "source": [
    "MAX_DEPTH = 10              #Maximum depth of decision tree\n",
    "\n",
    "#Suggest possible thresholds using mean, median, some intervals SD away from mean for category\n",
    "def possibleThreshold(xVals):\n",
    "    mean = np.mean(xVals)\n",
    "    sd = np.std(xVals)\n",
    "    thresholds = [np.median(xVals)]\n",
    "    intervals = np.arange(-4,4,0.2).tolist()\n",
    "    for i in range(0,len(intervals)):\n",
    "        thresholds.append(mean+intervals[i]*sd)\n",
    "    return thresholds\n",
    "\n",
    "print(possibleThreshold(X_train[:, 0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scc-322",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
